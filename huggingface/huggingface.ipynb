{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_classic.prompts import PromptTemplate\n",
    "\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.2 (Windows)', 'creationdate': '2023-09-09T07:52:17-04:00', 'author': 'U.S. Census Bureau', 'keywords': 'acsbr-015', 'moddate': '2023-09-12T14:44:47+01:00', 'title': 'Health Insurance Coverage Status and Type by Geography: 2021 and 2022', 'trapped': '/false', 'source': 'us_census\\\\acsbr-015.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='Health Insurance Coverage Status and Type \\nby Geography: 2021 and 2022\\nAmerican Community Survey Briefs\\nACSBR-015\\nIssued September 2023\\nDouglas Conway and Breauna Branch\\nINTRODUCTION\\nDemographic shifts as well as economic and govern-\\nment policy changes can affect people’s access to \\nhealth coverage. For example, between 2021 and 2022, \\nthe labor market continued to improve, which may \\nhave affected private coverage in the United States \\nduring that time.\\n1 Public policy changes included \\nthe renewal of the Public Health Emergency, which \\nallowed Medicaid enrollees to remain covered under \\nthe Continuous Enrollment Provision.\\n2 The American \\nRescue Plan (ARP) enhanced Marketplace premium \\nsubsidies for those with incomes above 400 percent \\nof the poverty level as well as for unemployed people.\\n3\\nIn addition to national policies, individual states and \\nthe District of Columbia can affect health insurance \\ncoverage by making Marketplace or Medicaid more')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read the ppdfs from the folder\n",
    "loader=PyPDFDirectoryLoader(\"./us_census\")\n",
    "\n",
    "documents=loader.load()\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "\n",
    "final_documents=text_splitter.split_documents(documents)\n",
    "final_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\Notes\\Projects\\Langchain_Agenti_AI_Dev\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "b:\\Notes\\Projects\\Langchain_Agenti_AI_Dev\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DP571\\.cache\\huggingface\\hub\\models--BAAI--bge-small-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "## Embedding Using Huggingface\n",
    "huggingface_embeddings= HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",      #sentence-transformers/all-MiniLM-l6-v2\n",
    "    model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings':True}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.30601454e-02 -1.45066977e-02 -2.10276134e-02  2.72683091e-02\n",
      "  4.53646928e-02  5.28341234e-02 -2.53758561e-02  3.61304060e-02\n",
      " -9.08312201e-02 -2.77017821e-02  7.97397867e-02  6.42474517e-02\n",
      " -3.54004055e-02 -4.04245406e-02 -1.13771502e-02  4.45296019e-02\n",
      " -3.88548896e-03 -3.79057694e-03 -4.54509854e-02  2.67047267e-02\n",
      " -2.05681697e-02  2.87432037e-02 -2.41201371e-02 -3.69412489e-02\n",
      "  1.92780886e-02  1.06194736e-02  3.21833231e-03  2.33253441e-03\n",
      " -4.29321565e-02 -1.64999172e-01  2.77011818e-03  2.68276725e-02\n",
      " -4.12894525e-02 -1.88446753e-02  1.58918854e-02  9.22327861e-03\n",
      " -2.00687572e-02  8.16561133e-02  3.89413014e-02  5.52223660e-02\n",
      " -3.69984247e-02  1.75318550e-02 -1.28967166e-02  2.80620705e-04\n",
      " -2.51580868e-02  4.59335325e-03 -2.39578784e-02 -5.76560525e-03\n",
      "  6.02942426e-03 -3.61178257e-02  3.84415239e-02 -1.75470184e-03\n",
      "  5.05656339e-02  6.02409020e-02  4.52067815e-02 -4.91434969e-02\n",
      "  1.82054006e-02 -1.46668348e-02 -2.53130645e-02  3.18243578e-02\n",
      "  5.15597872e-02 -9.32343956e-03 -2.61889219e-01  1.00012690e-01\n",
      "  1.34968329e-02  4.36564833e-02 -6.08387357e-03 -4.54129791e-03\n",
      " -3.26450095e-02 -4.28530797e-02 -5.28034419e-02  4.51760404e-02\n",
      " -4.90111038e-02  1.14363004e-02  3.36463191e-02  2.09723618e-02\n",
      "  1.38647472e-02  5.93815278e-03  1.49722816e-02 -8.11352581e-03\n",
      "  1.01394719e-02  2.79460046e-02 -6.45077555e-03 -4.83986810e-02\n",
      "  4.86142039e-02 -8.64626840e-02  5.24354167e-02 -3.35654914e-02\n",
      "  3.21200751e-02 -3.52677703e-02 -3.55472043e-02  1.33936852e-02\n",
      " -2.35920749e-03  3.77091020e-02  6.75866660e-03  3.44191939e-02\n",
      " -5.24614658e-03 -8.69453140e-03 -1.43432366e-02  3.42605799e-01\n",
      " -2.61229482e-02  9.80758574e-03 -2.25788858e-02  8.17077514e-03\n",
      " -9.10549983e-03 -6.63615763e-02 -3.31285340e-03  3.76487663e-03\n",
      "  1.78495701e-02  1.94206461e-02  1.89167727e-02 -2.34020669e-02\n",
      "  1.70285590e-02  3.59937809e-02 -5.00385724e-02 -2.86067966e-02\n",
      "  3.76006737e-02  1.95080470e-02  9.70122293e-02 -2.35507265e-02\n",
      " -5.60344709e-03  4.08104286e-02 -1.22215115e-02 -4.84442189e-02\n",
      "  1.59177892e-02  7.82315060e-02  5.22117317e-02  1.41182363e-01\n",
      "  3.60795595e-02 -3.56155708e-02  1.04116298e-01 -4.85003479e-02\n",
      " -9.04251263e-03 -3.47371621e-04 -3.86386458e-03  1.05186850e-02\n",
      " -1.18664224e-02  4.76750471e-02 -1.44307958e-02  4.32956554e-02\n",
      "  1.39372423e-02 -9.43199825e-03 -3.39481351e-03 -1.30119145e-01\n",
      " -2.24878900e-02  1.85143113e-01 -3.77383456e-02  4.94089499e-02\n",
      "  1.73504576e-02 -2.00506188e-02 -4.56999205e-02  6.15431666e-02\n",
      " -3.38922106e-02  3.41245309e-02 -3.52289602e-02  2.25264635e-02\n",
      " -3.88045819e-03  2.96608806e-02 -3.23118381e-02 -5.61316870e-02\n",
      "  5.52871451e-02 -3.27034183e-02 -4.70694490e-02  1.33565813e-02\n",
      "  4.41281460e-02 -2.02731676e-02 -1.62063148e-02 -5.46822958e-02\n",
      "  2.79455371e-02  9.90038551e-03  1.44527256e-02  5.46371303e-02\n",
      "  2.29170118e-02 -2.23384779e-02  9.18255076e-02  2.43631974e-02\n",
      " -3.52480002e-02 -8.27389769e-03 -5.45698591e-03 -5.42016998e-02\n",
      " -5.69422683e-03 -2.11965833e-02 -5.15157431e-02 -4.83904704e-02\n",
      " -1.58691630e-02 -3.49855460e-02 -6.40029311e-02  4.69647348e-02\n",
      "  5.08957691e-02 -1.47770531e-02 -2.62469426e-03  9.61359590e-03\n",
      " -5.30826859e-02  3.27618718e-02 -1.20410584e-02  1.89256237e-03\n",
      " -6.53932691e-02 -2.97078099e-02  4.61532064e-02 -3.11540402e-02\n",
      " -3.44942436e-02  2.73555350e-02  1.33985709e-02 -1.12298969e-02\n",
      " -5.48384665e-03  1.20182410e-02  3.20996679e-02 -7.33810812e-02\n",
      "  4.33215164e-02 -1.46466950e-02 -6.26264419e-03  4.07445841e-02\n",
      "  2.55041439e-02  1.34792307e-03  3.32123935e-02  2.35809460e-02\n",
      "  1.29890749e-02 -2.96592508e-02  9.96692572e-04  3.23757902e-02\n",
      "  3.47310081e-02  7.43660703e-02  8.83725360e-02 -2.74852782e-01\n",
      " -5.02360938e-03  6.73114136e-03  5.10847196e-03 -7.25276917e-02\n",
      " -5.16856425e-02 -3.50604765e-02  2.54639201e-02  5.96723426e-03\n",
      "  9.32260081e-02  6.52372539e-02 -1.24274055e-02 -2.26454679e-02\n",
      "  1.03852808e-01  2.69623492e-02 -5.88307828e-02  3.26073207e-02\n",
      " -2.70967241e-02 -1.62646826e-02  3.82242375e-03  1.43363990e-03\n",
      " -1.74210570e-03 -5.87847196e-02 -2.53608550e-06  8.17155614e-02\n",
      " -8.29946192e-04  6.18573278e-02 -5.67797832e-02 -7.95386136e-02\n",
      "  8.72028619e-03 -5.23827597e-02  4.91903760e-02 -1.34030487e-02\n",
      " -1.09614685e-01  6.37905151e-02  1.59761216e-02 -8.35732594e-02\n",
      " -1.80334579e-02 -5.23566641e-02 -2.67080627e-02 -2.57245135e-02\n",
      "  5.58587424e-02 -6.18519410e-02  1.82368960e-02 -1.30651994e-02\n",
      " -5.21241426e-02  4.50306907e-02  6.84902370e-02 -7.28626326e-02\n",
      "  4.47439170e-03  8.44443962e-03 -2.58527957e-02 -2.72554457e-02\n",
      " -8.25325679e-03  2.65438929e-02 -6.06658384e-02 -3.46958600e-02\n",
      "  2.65968833e-02 -1.06718922e-02 -6.09576283e-03  2.14285702e-02\n",
      "  4.35657194e-03  3.98480520e-02 -7.30904890e-03  7.62283336e-04\n",
      " -4.81284559e-02  9.06976406e-03 -2.74650976e-02 -6.46280423e-02\n",
      "  7.81241246e-03  6.36982440e-04  3.72855738e-02 -2.43166406e-02\n",
      " -2.94920206e-02  2.59610210e-02 -2.04743762e-02  2.99484655e-02\n",
      " -3.93521925e-03 -7.24741397e-03 -4.70116138e-02  4.60673198e-02\n",
      " -6.55132085e-02  1.94678549e-02  4.70718406e-02 -4.82363487e-03\n",
      "  1.85413193e-02  1.27155390e-02  9.35985427e-03 -1.63067412e-02\n",
      "  1.78641081e-02 -1.42972032e-02 -1.85641088e-02 -1.11412918e-02\n",
      " -2.76978798e-02 -1.63667859e-03  1.32831829e-02 -2.23142415e-01\n",
      "  5.02429754e-02  3.20568010e-02 -2.58731283e-02  7.37159234e-03\n",
      " -1.69072710e-02 -1.84587073e-02  1.52460411e-02 -1.25951404e-02\n",
      " -1.74231511e-02  4.49848175e-02  8.47080946e-02  1.25501961e-01\n",
      " -1.12586664e-02 -9.03833285e-03 -4.29150555e-03  7.40758404e-02\n",
      " -5.70530677e-03  2.40515154e-02 -4.09415364e-02  5.69056012e-02\n",
      " -6.37594983e-02  1.52565375e-01 -1.74385551e-02  1.57483015e-02\n",
      " -7.21550211e-02 -2.26559825e-02  3.81210558e-02 -4.17390764e-02\n",
      "  1.38446772e-02  1.97878554e-02  1.08574117e-02  1.14634298e-02\n",
      " -1.90665405e-02  6.13893345e-02  4.67911595e-03  1.12023680e-02\n",
      "  4.75128330e-02  4.35520662e-03  3.34495045e-02 -5.18546551e-02\n",
      " -1.82737987e-02  9.24016349e-03  2.57455069e-03  6.83404282e-02\n",
      " -3.80240977e-02 -5.42043298e-02 -7.67752901e-02 -8.67897924e-03\n",
      "  6.64248690e-02  9.31188744e-03 -3.73429991e-02 -2.34108837e-03\n",
      " -5.78063121e-03 -5.70392311e-02 -6.05431385e-03 -5.90126291e-02\n",
      "  3.92624214e-02 -8.48797429e-03 -1.47276325e-02  2.09183842e-02\n",
      "  5.32475375e-02 -7.08249286e-02  1.93986073e-02  6.82188198e-02]\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "import  numpy as np\n",
    "print(np.array(huggingface_embeddings.embed_query(final_documents[0].page_content)))\n",
    "print(np.array(huggingface_embeddings.embed_query(final_documents[0].page_content)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VectorStore Creation\n",
    "vectorstore=FAISS.from_documents(final_documents[:120],huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 U.S. Census Bureau\n",
      "WHAT IS HEALTH INSURANCE COVERAGE?\n",
      "This brief presents state-level estimates of health insurance coverage \n",
      "using data from the American Community Survey (ACS). The  \n",
      "U.S. Census Bureau conducts the ACS throughout the year; the \n",
      "survey asks respondents to report their coverage at the time of \n",
      "interview. The resulting measure of health insurance coverage, \n",
      "therefore, reflects an annual average of current comprehensive \n",
      "health insurance coverage status.* This uninsured rate measures a \n",
      "different concept than the measure based on the Current Population \n",
      "Survey Annual Social and Economic Supplement (CPS ASEC). \n",
      "For reporting purposes, the ACS broadly classifies health insurance \n",
      "coverage as private insurance or public insurance. The ACS defines \n",
      "private health insurance as a plan provided through an employer \n",
      "or a union, coverage purchased directly by an individual from an \n",
      "insurance company or through an exchange (such as healthcare.\n"
     ]
    }
   ],
   "source": [
    "## Query using Similarity Search\n",
    "query=\"WHAT IS HEALTH INSURANCE COVERAGE?\"\n",
    "relevant_docments=vectorstore.similarity_search(query)\n",
    "\n",
    "print(relevant_docments[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'HuggingFaceEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000016B5D333230> search_kwargs={'k': 3}\n"
     ]
    }
   ],
   "source": [
    "retriever=vectorstore.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":3})\n",
    "print(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']= \"key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hugging Face Hub is an platform with over 350k models, 75k datasets, and 150k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DP571\\AppData\\Local\\Temp\\ipykernel_14552\\386166796.py:3: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  hf=HuggingFaceHub(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'InferenceClient' object has no attribute 'post'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      3\u001b[39m hf=HuggingFaceHub(\n\u001b[32m      4\u001b[39m     repo_id=\u001b[33m\"\u001b[39m\u001b[33mmistralai/Mistral-7B-v0.1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     model_kwargs={\u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m:\u001b[32m0.1\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m\"\u001b[39m:\u001b[32m500\u001b[39m}\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m )\n\u001b[32m      8\u001b[39m query=\u001b[33m\"\u001b[39m\u001b[33mWhat is the health insurance coverage?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mhf\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mb:\\Notes\\Projects\\Langchain_Agenti_AI_Dev\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:375\u001b[39m, in \u001b[36mBaseLLM.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    366\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m     **kwargs: Any,\n\u001b[32m    372\u001b[39m ) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    373\u001b[39m     config = ensure_config(config)\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    385\u001b[39m         .generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m    386\u001b[39m         .text\n\u001b[32m    387\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mb:\\Notes\\Projects\\Langchain_Agenti_AI_Dev\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:786\u001b[39m, in \u001b[36mBaseLLM.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    779\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     prompt_strings = [p.to_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mb:\\Notes\\Projects\\Langchain_Agenti_AI_Dev\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1008\u001b[39m, in \u001b[36mBaseLLM.generate\u001b[39m\u001b[34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     run_managers = [\n\u001b[32m    991\u001b[39m         callback_manager.on_llm_start(\n\u001b[32m    992\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1006\u001b[39m         )\n\u001b[32m   1007\u001b[39m     ]\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) > \u001b[32m0\u001b[39m:\n\u001b[32m   1016\u001b[39m     run_managers = [\n\u001b[32m   1017\u001b[39m         callback_managers[idx].on_llm_start(\n\u001b[32m   1018\u001b[39m             \u001b[38;5;28mself\u001b[39m._serialized,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1025\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m missing_prompt_idxs\n\u001b[32m   1026\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mb:\\Notes\\Projects\\Langchain_Agenti_AI_Dev\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:812\u001b[39m, in \u001b[36mBaseLLM._generate_helper\u001b[39m\u001b[34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[39m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate_helper\u001b[39m(\n\u001b[32m    802\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    803\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    808\u001b[39m     **kwargs: Any,\n\u001b[32m    809\u001b[39m ) -> LLMResult:\n\u001b[32m    810\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    811\u001b[39m         output = (\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    815\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[32m    816\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    819\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m    820\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._generate(prompts, stop=stop)\n\u001b[32m    821\u001b[39m         )\n\u001b[32m    822\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    823\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mb:\\Notes\\Projects\\Langchain_Agenti_AI_Dev\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1502\u001b[39m, in \u001b[36mLLM._generate\u001b[39m\u001b[34m(self, prompts, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1499\u001b[39m new_arg_supported = inspect.signature(\u001b[38;5;28mself\u001b[39m._call).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1500\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m   1501\u001b[39m     text = (\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1503\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[32m   1504\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call(prompt, stop=stop, **kwargs)\n\u001b[32m   1505\u001b[39m     )\n\u001b[32m   1506\u001b[39m     generations.append([Generation(text=text)])\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations=generations)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mb:\\Notes\\Projects\\Langchain_Agenti_AI_Dev\\.venv\\Lib\\site-packages\\langchain_community\\llms\\huggingface_hub.py:138\u001b[39m, in \u001b[36mHuggingFaceHub._call\u001b[39m\u001b[34m(self, prompt, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    135\u001b[39m _model_kwargs = \u001b[38;5;28mself\u001b[39m.model_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    136\u001b[39m parameters = {**_model_kwargs, **kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m(\n\u001b[32m    139\u001b[39m     json={\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33mparameters\u001b[39m\u001b[33m\"\u001b[39m: parameters}, task=\u001b[38;5;28mself\u001b[39m.task\n\u001b[32m    140\u001b[39m )\n\u001b[32m    141\u001b[39m response = json.loads(response.decode())\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "\u001b[31mAttributeError\u001b[39m: 'InferenceClient' object has no attribute 'post'"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "hf=HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "    model_kwargs={\"temperature\":0.1,\"max_length\":500}\n",
    "\n",
    ")\n",
    "query=\"What is the health insurance coverage?\"\n",
    "hf.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\Notes\\Projects\\Langchain_Agenti_AI_Dev\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DP571\\.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-v0.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]b:\\Notes\\Projects\\Langchain_Agenti_AI_Dev\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:798: UserWarning: Not enough free disk space to download the file. The expected file size is: 9942.98 MB. The target location C:\\Users\\DP571\\.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-v0.1\\blobs only has 5597.73 MB free disk space.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Hugging Face models can be run locally through the HuggingFacePipeline class.\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "hf = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"temperature\": 0, \"max_new_tokens\": 300}\n",
    ")\n",
    "\n",
    "llm = hf \n",
    "llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following piece of context to answer the question asked.\n",
    "Please try to provide the answer only based on the context\n",
    "\n",
    "{context}\n",
    "Question:{question}\n",
    "\n",
    "Helpful Answers:\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(template=prompt_template,input_variables=[\"context\",\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrievalQA=RetrievalQA.from_chain_type(\n",
    "    llm=hf,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\":prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"DIFFERENCES IN THE\n",
    "UNINSURED RATE BY STATE\n",
    "IN 2022\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Use the following piece of context to answer the question asked.\n",
      "Please try to provide the answer only based on the context\n",
      "\n",
      "comparison of ACS and CPS ASEC measures \n",
      "of health insurance coverage, refer to < www.\n",
      "census.gov/topics/health/health-insurance/\n",
      "guidance.html >.\n",
      "9 Respondents may have more than one \n",
      "health insurance coverage type at the time \n",
      "of interview. As a result, adding the total \n",
      "number of people with private coverage and \n",
      "the total number with public coverage will \n",
      "sum to more than the total number with any \n",
      "coverage.• From 2021 to 2022, nine states \n",
      "reported increases in private \n",
      "coverage, while seven reported \n",
      "decreases (Appendix Table B-2). \n",
      "DIFFERENCES IN THE \n",
      "UNINSURED RATE BY STATE \n",
      "IN 2022\n",
      "In 2022, uninsured rates at the \n",
      "time of interview ranged across \n",
      "states from a low of 2.4 percent \n",
      "in Massachusetts to a high of 16.6 \n",
      "percent in Texas, compared to the \n",
      "national rate of 8.0 percent.10 Ten \n",
      "of the 15 states with uninsured \n",
      "10 The uninsured rates in the District \n",
      "of Columbia and Massachusetts were not \n",
      "statistically different.rates above the national aver -\n",
      "\n",
      "percent (Appendix Table B-5). \n",
      "Medicaid coverage accounted \n",
      "for a portion of that difference. \n",
      "Medicaid coverage was 22.7 per -\n",
      "cent in the group of states that \n",
      "expanded Medicaid eligibility and \n",
      "18.0 percent in the group of nonex -\n",
      "pansion states.\n",
      "CHANGES IN THE UNINSURED \n",
      "RATE BY STATE FROM 2021 \n",
      "TO 2022\n",
      "From 2021 to 2022, uninsured rates \n",
      "decreased across 27 states, while \n",
      "only Maine had an increase. The \n",
      "uninsured rate in Maine increased \n",
      "from 5.7 percent to 6.6 percent, \n",
      "although it remained below the \n",
      "national average. Maine’s uninsured \n",
      "rate was still below 8.0 percent, \n",
      "21 Douglas Conway and Breauna Branch, \n",
      "“Health Insurance Coverage Status and Type \n",
      "by Geography: 2019 and 2021,” 2022, < www.\n",
      "census.gov/content/dam/Census/library/\n",
      "publications/2022/acs/acsbr-013.pdf >.\n",
      "\n",
      "library/publications/2022/acs/acsbr-013.pdf >.\n",
      "39 In 2022, the private coverage rates were \n",
      "not statistically different in North Dakota and \n",
      "Utah.Figure /five.tab/period.tab\n",
      "Percentage of Uninsured People for the /two.tab/five.tab Most Populous Metropolitan \n",
      "Areas/colon.tab /two.tab/zero.tab/two.tab/one.tab and /two.tab/zero.tab/two.tab/two.tab\n",
      "(Civilian, noninstitutionalized population) /uni00A0\n",
      "* Denotes a statistically signiﬁcant change between 2021 and 2022 at the 90 percent conﬁdence level.\n",
      "Note: For information on conﬁdentiality protection, sampling error, nonsampling error, and deﬁnitions in the American Community\n",
      "Survey, refer to <https://www2.census.gov/programs-surveys/acs/tech_docs/accuracy/ACS_Accuracy_of_Data_2022.pdf>.\n",
      "Source: U.S. Census Bureau, 2021 and 2022 American Community Survey, 1-year estimates. Boston-Cambridge-Newton/comma.tab MA-NH\n",
      "San Francisco-Oakland-Berkeley/comma.tab CA\n",
      "*Detroit-Warren-Dearborn/comma.tab MI\n",
      "Question:DIFFERENCES IN THE\n",
      "UNINSURED RATE BY STATE\n",
      "IN 2022\n",
      "\n",
      "Helpful Answers:\n",
      " 1.\n",
      " 2.\n",
      " 3.\n",
      " 4.\n",
      " 5.\n",
      " 6.\n",
      " 7.\n",
      " 8.\n",
      " 9.\n",
      " 10.\n",
      " 11.\n",
      " 12.\n",
      " 13.\n",
      " 14.\n",
      " 15.\n",
      " 16.\n",
      " 17.\n",
      " 18.\n",
      " 19.\n",
      " 20.\n",
      " 21.\n",
      " 22.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the QA chain with our query.\n",
    "result = retrievalQA.invoke({\"query\": query})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
